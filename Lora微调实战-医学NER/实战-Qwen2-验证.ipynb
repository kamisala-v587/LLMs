{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0324cb7a",
   "metadata": {},
   "source": [
    "本实验使用Qwen2.5-1.5B模型 测试\n",
    "仅用于学习不用于生成最终模型 - 因此数据量也较低"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174778b3",
   "metadata": {},
   "source": [
    "### 1. 数据处理 - Tokenizer\n",
    "#### 1.1 加载数据 - Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f96d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['投活络效灵丹加味：当归、丹参各１５ｇ，生乳香、生没药各６ｇ，柴胡１２ｇ，白芍、黄芩、大黄各１０ｇ，蒲公英３０ｇ，甘草５ｇ',\n",
       "  '目的补气健脾升清法治疗糖尿病性功能性消化不良的临床效果',\n",
       "  '结论温脾散穴位敷贴联合理中复元方可改善脾虚痰瘀型慢性萎缩性胃炎患者临床症状（尤其是胃窦大弯侧、胃体小弯侧萎缩），值得推广应用',\n",
       "  '完带汤治疗肠道易激综合征６０例',\n",
       "  '结论：辨证针刺治疗ＦＤ能明显改善患者的生活质量，为治疗ＦＤ的有效方法'],\n",
       " 'label': [\"{'活络效灵丹': '方剂', '当归': '中药', '丹参': '中药', '生乳香': '中药', '生没药': '中药', '柴胡': '中药', '黄芩': '中药', '大黄': '中药', '蒲公英': '中药', '甘草': '中药'}\",\n",
       "  \"{'糖尿病性功能性消化不良': '西医诊断'}\",\n",
       "  \"{'温脾散穴位敷贴': '中医治疗', '脾虚痰瘀': '中医证候', '慢性萎缩性胃炎': '西医诊断'}\",\n",
       "  \"{'完带汤': '方剂', '肠道易激综合征': '西医诊断'}\",\n",
       "  \"{'辨证针刺': '中医治疗'}\"]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "dev = pd.read_csv(\"data/dev.csv\")[:50] # 仅前50条数据用于测试\n",
    "dev_ds = Dataset.from_pandas(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69d77d",
   "metadata": {},
   "source": [
    "#### 1.2 Tokenization\n",
    "+ 加载tokenizer \n",
    "+ 定义process function：prompt方程\n",
    "+ 处理dataset为 [input_id, attention_mask,labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba79a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import AutoTokenizer\n",
    "model_dir =\"/Users/luyi/PythonProjects/Atomy/03LLM微调/命名实体微调实战/qwen/Qwen2-1___5B-Instruct\" # 定义本地路径\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False, trust_remote_code=True,padding_side='left') # 加载tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac315bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义process function:\n",
    "def process_func(example):\n",
    "    MAX_LENGTH = 200\n",
    "    \n",
    "    instruction = \"\"\"你是一个文本实体识别领域的医学专家，你需要从给定的句子中提取中医诊断,中药,中医治疗, 方剂, 西医治疗, 西医诊断 '其他治疗'等. 以 json 格式输出, 如 {'口苦': '临床表现','肺结核': '西医诊断'} 注意: 1. 输出的每一行都必须是正确的json字符串. 2.找不到任何实体时, 输出\"没有找到任何实体\".\"\"\"\n",
    "    instructions_messages= [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{example['text']}\"}\n",
    "    ]\n",
    "\n",
    "    instructions_chatTamplate = tokenizer.apply_chat_template(instructions_messages, tokenize=True, add_generation_prompt=False,return_dict=True)\n",
    "\n",
    "    input_ids = instructions_chatTamplate['input_ids']\n",
    "    attention_mask = instructions_chatTamplate['attention_mask']\n",
    "    \n",
    "    # 限制最大长度做截断处理\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "    else:\n",
    "        pad_len = MAX_LENGTH - len(input_ids)\n",
    "        input_ids = [tokenizer.pad_token_id] * pad_len + input_ids\n",
    "        attention_mask = [0] * pad_len + attention_mask\n",
    "    \n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5f6073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8955ffda1ebb444194f07f8158a6dc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_dataset = dev_ds.map(process_func, remove_columns=dev_ds.column_names,num_proc=4) \n",
    "# 删除column_names 保证简洁性\n",
    "# 多线程处理数据 加速数据处理速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d18aef",
   "metadata": {},
   "source": [
    "### 2. 验证模型\n",
    "#### 2.1 加载原始模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21457f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91155c0",
   "metadata": {},
   "source": [
    "#### 2.2 加载Lora参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b231d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 1,552,946,688 || trainable%: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "# 加载LoRA权重（轻量化推理）\n",
    "peft_model = PeftModel.from_pretrained(model, \"./lora_weights_qwen2.5\", inference_mode=True)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f3c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def predict(dataset, model, tokenizer):\n",
    "    \"\"\"\n",
    "    修正后的预测函数：支持批量/单条样本，处理维度问题，优化切片逻辑\n",
    "    :param dataset: 处理后的Dataset（如dev_ds_processed[:5]）\n",
    "    :param model: 加载的LoRA/Qwen2模型\n",
    "    :param tokenizer: 初始化后的tokenizer\n",
    "    :return: 模型生成的实体识别结果列表\n",
    "    \"\"\"\n",
    "    # 步骤1：提取数据并转换为二维张量（适配批量输入）\n",
    "    input_ids = torch.tensor(dataset['input_ids']).to(model.device)\n",
    "    attention_mask = torch.tensor(dataset['attention_mask']).to(model.device)\n",
    "    \n",
    "    # 步骤2：模型生成（禁用梯度计算，节省显存）\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.7,  # 降低随机性，让JSON输出更稳定\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id,  # 指定pad_token_id\n",
    "            eos_token_id=tokenizer.eos_token_id   # 指定结束token\n",
    "        )\n",
    "    \n",
    "    # 步骤3：修正切片逻辑——去掉输入部分，仅保留模型生成的内容\n",
    "    # input_ids.shape[1]是单条样本的序列长度（MAX_LENGTH）\n",
    "    input_seq_len = input_ids.shape[1]\n",
    "    generated_ids = generated_ids[:, input_seq_len:]  # 批量切片\n",
    "    \n",
    "    # 步骤4：解码结果（跳过特殊token，得到纯净文本）\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)    \n",
    "    # # 打印结果\n",
    "    # for idx, res in enumerate(response):\n",
    "    #     print(f\"样本{idx+1}生成结果：\\n{res}\\n\" + \"-\"*80)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "467fb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_base = predict(dev_dataset, model, tokenizer)\n",
    "response_lora = predict(dev_dataset, peft_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f7f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,ast\n",
    "def f1_helper(response):\n",
    "    dataset = {}\n",
    "    for idx,res in enumerate(response):\n",
    "        if idx == 16:\n",
    "            pass\n",
    "        pattern = r\"\\{[\\s\\S]*?\\}\"  # 匹配JSON大括号片段\n",
    "        res = re.search(pattern, res)\n",
    "        res = res.group() if res else \"{}\"\n",
    "        label = dev['label'][idx]\n",
    "        # print(res,label)\n",
    "        res = ast.literal_eval(res)\n",
    "        label = ast.literal_eval(label) # k 是 '腹痛'症状 v 是 '临床表现'\n",
    "        # 筛选key\n",
    "        samekeys=set()\n",
    "        diffkeys1=set()\n",
    "        diffkeys2=set()\n",
    "        for k in label:\n",
    "            if k in res:\n",
    "                samekeys.add(k)\n",
    "            else:\n",
    "                diffkeys1.add(k)\n",
    "        for k in res:\n",
    "            if k not in samekeys:\n",
    "                diffkeys2.add(k) \n",
    "        \n",
    "        # 处理相同的\n",
    "        for k in samekeys:\n",
    "            v1 = label[k]\n",
    "            v2 = res[k]\n",
    "            if v1 not in dataset:\n",
    "                dataset[v1] = {\"FN\":0,\"FP\":0,\"TP\":0} \n",
    "            if v1 == v2:\n",
    "                dataset[v1][\"TP\"]+=1\n",
    "            elif v1!=v2:\n",
    "                dataset[v1][\"FP\"]+=1\n",
    "                if v2 in dataset:\n",
    "                    dataset[v2][\"FN\"]+=1\n",
    "        for k in diffkeys1:\n",
    "            v1 = label[k]\n",
    "            if v1 not in dataset:\n",
    "                dataset[v1] = {\"FN\":0,\"FP\":0,\"TP\":0} \n",
    "            dataset[v1][\"FP\"]+=1\n",
    "        for k in diffkeys2:\n",
    "            v2 = res[k]\n",
    "            if v2 in dataset:\n",
    "                dataset[v2][\"FN\"]+=1\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3ed45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(metric_dict: dict, key: str) -> float:\n",
    "    \"\"\"\n",
    "    根据实体类型的TP/FP/FN字典，输入key计算对应F1分数\n",
    "    :param metric_dict: 包含各实体类型TP/FP/FN的字典（如你提供的字典）\n",
    "    :param key: 要查询的实体类型key（如'中药'/'西医诊断'）\n",
    "    :return: 该类别的F1分数（保留4位小数）\n",
    "    \"\"\"\n",
    "    # 检查key是否存在于字典中\n",
    "    if key not in metric_dict:\n",
    "        raise KeyError(f\"Key '{key}' 不存在于字典中，可选key: {list(metric_dict.keys())}\")\n",
    "    \n",
    "    # 提取该key对应的TP、FP、FN\n",
    "    tp = metric_dict[key]['TP']\n",
    "    fp = metric_dict[key]['FP']\n",
    "    fn = metric_dict[key]['FN']\n",
    "    \n",
    "    # 计算精确率（处理分母为0的情况）\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    # 计算召回率（处理分母为0的情况）\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    # 计算F1分数（处理分母为0的情况）\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    # 保留4位小数，便于阅读\n",
    "    return round(f1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6647d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中药的F1分数：0.8496\n",
      "西医诊断的F1分数：0.7037\n",
      "临床表现的F1分数：0.6667\n",
      "中药的F1分数：0.5301\n",
      "西医诊断的F1分数：0.5769\n",
      "临床表现的F1分数：0.3704\n"
     ]
    }
   ],
   "source": [
    "dataset_base = f1_helper(response_base)\n",
    "# 示例1：查询'中药'的F1分数\n",
    "f1_herb = get_f1_score(dataset_base, '中药')\n",
    "print(f\"中药的F1分数：{f1_herb}\")\n",
    "\n",
    "# 示例2：查询'西医诊断'的F1分数\n",
    "f1_west_diag = get_f1_score(dataset_base, '西医诊断')\n",
    "print(f\"西医诊断的F1分数：{f1_west_diag}\")\n",
    "\n",
    "# 示例3：查询'临床表现'的F1分数\n",
    "f1_symptom = get_f1_score(dataset_base, '临床表现')\n",
    "print(f\"临床表现的F1分数：{f1_symptom}\")\n",
    "\n",
    "\n",
    "dataset_lora = f1_helper(response_lora)\n",
    "# 示例1：查询'中药'的F1分数\n",
    "f1_herb = get_f1_score(dataset_lora, '中药')\n",
    "print(f\"中药的F1分数：{f1_herb}\")\n",
    "\n",
    "# 示例2：查询'西医诊断'的F1分数\n",
    "f1_west_diag = get_f1_score(dataset_lora, '西医诊断')\n",
    "print(f\"西医诊断的F1分数：{f1_west_diag}\")\n",
    "\n",
    "# 示例3：查询'临床表现'的F1分数\n",
    "f1_symptom = get_f1_score(dataset_lora, '临床表现')\n",
    "print(f\"临床表现的F1分数：{f1_symptom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4a2e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'中药': {'FN': 9, 'FP': 8, 'TP': 48},\n",
       " '方剂': {'FN': 10, 'FP': 4, 'TP': 3},\n",
       " '西医诊断': {'FN': 6, 'FP': 10, 'TP': 19},\n",
       " '中医证候': {'FN': 4, 'FP': 4, 'TP': 3},\n",
       " '中医治疗': {'FN': 2, 'FP': 3, 'TP': 3},\n",
       " '其他治疗': {'FN': 3, 'FP': 2, 'TP': 0},\n",
       " '临床表现': {'FN': 5, 'FP': 4, 'TP': 9},\n",
       " '中医治则': {'FN': 1, 'FP': 3, 'TP': 3},\n",
       " '西医治疗': {'FN': 1, 'FP': 2, 'TP': 2}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b615c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'中药': {'FN': 5, 'FP': 34, 'TP': 22},\n",
       " '方剂': {'FN': 7, 'FP': 4, 'TP': 3},\n",
       " '西医诊断': {'FN': 8, 'FP': 14, 'TP': 15},\n",
       " '中医证候': {'FN': 4, 'FP': 4, 'TP': 3},\n",
       " '中医治疗': {'FN': 4, 'FP': 5, 'TP': 1},\n",
       " '其他治疗': {'FN': 0, 'FP': 1, 'TP': 1},\n",
       " '临床表现': {'FN': 9, 'FP': 8, 'TP': 5},\n",
       " '中医治则': {'FN': 5, 'FP': 3, 'TP': 3},\n",
       " '西医治疗': {'FN': 3, 'FP': 2, 'TP': 2}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd277e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tunning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
